---
title: "Generic Drugs are Cheap Knockoffs Bypassing FDA Regulatory Policy"
categories: "blog"
tags: ""
headline: ""
author:
  name: "David Conner"
excerpt: ""
---

- TODO: describe symmetry in enantiomers, but their lack of symmetry
  in genetic networks.
- TODO: clarify pharmakinetics metrics: Pi, Pk, etc
- TODO: brief overview on most frequently used methods of racemic
  filtration and how they limit ChemE design
- TODO: move Navier Stokes content to the end


Intro
==========



- the main point: although pharmaceutical companies could have been
  ignorant of (this) in the 1980's, the time is coming when it will be
  clear they are cognizant of problems related to generic formulations
  that are causing side-effects and, perhaps, chronic health
  consequences with misattributed cause. (Although I'm admittedly not
  well-read on this issue), I know that many of these consequences of
  generic medications are as yet unknown in the academic and medical
  literature. This means that your M.D. or your Psychiatrist remain
  unaware of issues indicating contraindiction when they decide what
  to prescribe, whether it needs to be generic or brand-name and,
  critically, what impact the new prescription will have on the state
  of your health or psych.

  - (...) this doesn't necessarily indicate full-blown
    health-crisis. To the contrary, this could signal two very
    beneficial opportunities: one, economic, in the development of
    intellectual property around the more efficient production of
    parma; the other, academic and economic, in the development of
    more advanced research methodologies which expand our insight into
    which genetic subnetworks are responsible for side-effects, better
    informing the need to contraindicate.

The significance of both of these potential economic opportunities is
as-yet unclear to me. In contrast, of the two opportunities above,
neither is as significant as a predictive medicine imaging development
allowing [CYP]() enzyme distribution in the liver to become known --
preferably with the details corresponding to their spatial
distribution. In cirrosis, even cases of alcoholism which don't
qualify as presenting with cirrosis, the spatial distribution of CYP
enzymes causes the patient to present with specific (symptomological)
patterns. Wherever there is liver scarring, there is disruption in the
production and distribution in CYP enzymes.

Any methodological development providing significant accuracy in
assessment of CYP distribution and production would be immensely
useful, if it at least provides basic insight into plasma
concentration response. Via data science, if such a method also
enabled insight into a medications impact on relevant genetic networks
and at least those adjacent to the prescription's target mechanism,
this mechanism further augments a doctor's ability to quickly respond
to a patients needs. Quantifiably, which is critical for psychiatry
and neurology. Finally, if this method also provides a spatial
distribution of CYP enzymes in the liver, this would empower research
related to pharmakinetics of metabolic pathways, as well as a
patient's lifestyle impact thereto. For example, researchers might be
able to quantify yoga's impact on glandular, gastrointestinal and
metabolic processes.

Generally, any time you tighten the patient-provider feedback loop in
healthcare, it results in these organizational benefits to patient,
provider and payer:

- it yields price reductions via logistic changes of patient-care
  processes.
- it decreases the risk of adverse outcomes, both short-term and
  long-term, as well as the costs related to difficulty of diagnosis,
  estimating trajectory of prognosis and shifting course in
  treatment. these are each a relief to administrators, but firstmost
  to patients and doctors
- it results in a more complete patient history profile. this not only
  benefits the patient and doctor, immediately, but also potential
  researchers in the future.
- it disrupts an industry which is slow to change by incentivizing
  innovation.

**All of the above result in costs savings, as well as healthier and
happier patient outcomes.** Assessing CYP enzyme distribution is one
of many innovations which will disrupt healthcare. Still, this doesn't
seem to be a nascent development widely proclaimed by American
media. The lack of discussion likely results from the esoteric nature
of metabolic pathways.


This could be accomplished via the
administration of an isotope and data science on MRI or some other
imaging technology. Such a method, if it were cheaply available to
doctors and psychiatrists, would save months of time in situations
where one swaps prescription medications, changes dosages, waits, and
hopes for the best. Further, as an example, if a patient engaged in
specific dietary habits dietary concerns that dynamically result in
significant fluctuations to metabolic enzyme production, distribution
and re-activation in the liver, then *the patient-provider feedback
loop* becomes tighter and better prescription decisions are made
earlier. These are incredibly difficult issues that health-care
providers, especially psychiatrists, overcome when making prescription
and dosage decisions. Finally, **there is no such thing as predictive
medication without CYP enzyme profiling**. There may be corner-cases,
but as predictive medication applies to prescription decisions, there
are no useful insights without an assessment of metabolization. It is
misleading to believe that genotype alone tells you which medications
to prescript. Such a perspective is oblivious to epigenetics and
metanomics, which are statisical programs encoded in
[biophysics](). The fluctuations in and state of CYP enzyme
production, distribution and activation are far more critical. Even
OTC medications -- including specific OTC's I have in mind, but won't
mention because of issues of potential abuse with psychiatric
medication -- interfere with not only the CYP enzyme itself, but also
the upstream PXR gene which upregulates the CYP enzyme's
production. So, administer this OTC and dramatically achieve double
the metabolic rate for this particular psychiatric drug. Therefore,
the patient could potentially destabalize themselves. And, I should
also clarify, using knowledge of CYP enzymes or relaying knowledge to
people who don't have an M.D. could be exceedingly dangerous and
result in overdose. This underscores the insufficiency of genotype in
predicting patient outcome. It simply is not well-correlated unless
there is assessment of the patient's metabolic dynamics and diet.

    for medication would become more clear
    prescription-titration and with a bit of subsequent data science
    to match predictive medicine, genotypes to

[dsa]:

## Production Generics Have Unpredictable Effects on Genetic Pathways

Why? Unless research has been conducted on varying the racemic
composition, then enantiomers composing the racemic composition for a
generic depend foremost on the economics of that drugs
production. This is not true in all cases, since there are some drugs
where it is recognized that side-effects and contraindications emerge
when the racemic composition of enantiomers is not constrained to
specifications. For brand-name drug manufactures, especially those
whose patented production pathways


- Considering the profit margins, it's absolutely pathetic for
  generics manufacturers to NOT filter the drug's to some specific
  racemic composition. That is absolutely unacceptable, unless the
  chemical reaction pathways and filtration mechanisms render such
  stereospecific filtration of enantiomers untenable, which *IS.
  often the case.

- what is clear: this is a problem. To me, the scope of these issues
  is not yet clear. In many cases, pharmaceutical production must take
  into account the proportion of enantiomers in the final product --
  for safety reasons. Not controlling these quantities would result in
  unpredictable side effects and health concern. This should have been
  well known in pharmaceutical research for decades, at least. After
  all, you can't take more than two weeks of Organic Chemistry without
  learning about enantiomers, stereocenters and the fair difficulty
  relating to filtering reaction products along the basis of some
  [stereocenter](). Thus, it is a well-known problem amongst graduates
  of *any major* requiring Organic Chemistry as a prerequisite.

  Most graduates won't understand the details necessary for evaluating
  [pharmakinetics](), metabolic specificity and impact of
  enantiomer-specificity to genetic subnetworks. Further, this is
  knowledge which is highly specific to the application at hand and
  the chemical & pharmaceutical properties of specific chemical
  families and reaction pathways. Further, much research I've seen
  does not document or quantify the racemic profile. i.e. There is no
  data!

For compounds where enantiomers along stereocenter(s) result in mirror
molecules whose pharmakinetics of enzyme-activation aren't impacted,
there is no change in the pharmacological properties.  There may still
be differences related to metabolization rates of enantiomers, since
[CYP-XXXX]() enzymes those can have similar (stereo-specifically)
dependent pharmakinetic metrics. Here, there are not so many effects
to genetic subnetworks related to the proteins that engage with the
pharmaceutical; instead, it's mostly the racemic composition of the
plasma concentration of the drug that changes. This means that if your
liver metabolizes one enantiomer at faster rates than others, then the
racemicity of plasma concentrations of the drug changes over time.


If such racemicity of drug plasma concentrations could be measured,
then it would provide immense insight into the specific genetic
pathways responsible for side effects and drugs restricted by known
contraindicative effects, since your [Phase III] trial could indicate
when side effects emerged, interpolating the racemic mixture at that
point. However, like I mentioned already, the racemic
composition. *this is not an easy quantity to measure*; the method, if
cheap, is highly specific to the chemicals for which you are
measuring. With alternate pharmakinetics, either pharmacological or
metabolic, connecting how this changes over time to the drug's actions
can critically empower inferences for research. In fact, for any drug
that has side-effects which are unclear, if a basis for measuring
changes to racemic composition of plasma concentrations can be
developed, it will clarify the pharmacological basis for those
side-effects.

#### Scientists Call This [Moving the Lampposts]

Whether the above is a useful technique for changing *how reseach is
conducted* or *how expediently and completely data can be connected*,
whenever someone does so, they ["move the lampposts"](). The idiom
refers to moving the light forward, enabling new inferential bases for
experimental methodology, changing how researchers engage in deductive
reasoning and inductively expanding their development of new
hypothesis. Such lamppost-moving developments completely change how
research funding is allocated and -- **if you understand what
"diffeomorphic epistemology" means** -- then accelerates the
development of knowledge with regard to specific subjects that exceeds
the common person's expectation. It's something that the true
intellectual greats seem to intuitively focus on; not that I am such,
nor is such a methodological tool of "measuring enantiomers in blood
plasma" practical or effective. I simply wish that it was. even far
before I knew of this idiom -- since I was always challenging
conventional belief and being smacked down by common counter-arguments
-- I was constantly searching for methods that would change how people
form confirm hypotheses, collect data or non-scientific beliefs about
other phenomena: *a true non-NPC*.

####

How many stereocenters does a particular pharmaceutical have?
Roughly, it correlates linearly to the complexity of the
molecules. Along how many stereocenters could a pharmaceutical be
filtered during its production? That slightly different quantity
relates to the number of reaction methods which could produce reaction
products with mirrored chemical structure. Keep in mind, such
production is a problem of chemical engineering, which requires
sourcing precursors whose production stretches across a supply
chain. Simply measuring the racemic composition can be difficult: a
process specific to reaction pathways and the family of chemical
products where the methods to measure my be constrained by the
electrochemical properties of the products. Further, such methods and
specifics of production are an appealing basis for intellectual
property in the pharmaceutical industry.

So, along the supply-chain and the chemical production pipeline, any
point where you introduce racemic filtration increases complexity,
cost, dependence on intellectual property and, most critically,
time. Since the methods for filtering mirror-molecules are expensive
in time, then doing so always introduces bottlenecks to your
production process. In chemical engineering, pharmaceutical
engineering, biotech and nanotech, this and other phenomena affect how
businesses design pipelines, source precursors, schedule production to
account for demand, make decisions predicated upon supply-side
economics or seasonal trends. This is a big problem (TODO: list
racemic filtration mechanisms)

### In 2011, the DEA Manipulated Pharmaceutical Supply-Chain for Downstream Profit

In 2011, the DEA artificially manipulated the production of adderal by
diverting supply of a critical precursor to its new competitors,
Vyvanse and Concerta. This created an adderal shortage, so it became
necessary for doctors to phase their customers over to the patented
alternative *Vyvanse*. Why? Because the DEA has a hard-on for
enforcing drug policy and crossed streams with the pharmaceutical
industry's greed.  Such greed is empowered by data that models of
decision-trees of both doctors prescription-practices as well as
consumer's tendency to switch medications -- which they usually don't
if essentially the same effects are guaranteed. Since consumers
couldn't get their prescription filled, they'd call their doctor,
who'd switch them to a prescription where your insurance company would
need to cover the 4x-5x price difference. CASH IN POCKET, for drug
companies. And all it took was causing a amphetamine addiction scare
by manipulating the American news racket to provoke the DEA's
knee-jerk response to divert precursors, ostensibly to control
addiction. Nevermind that Vyvanse is a pro-drug and takes hours to
become effective -- for ADD, this means your child's medication isn't
active until 12:00pm at school. They're medicated by lunchtime and the
pro-drug doesn't wear off until far too late, so they may have
problems sleeping. But the DEA? They get to act like their nigh
monopoly control over precursors to amphetamine production resulted in
real policy results. And drug companies? PROFIT ALL THE WAY TO THE
BANK, knowing once consumers switch, they won't be likely to switch
back. It's the perfect *LAUNCH STRATEGY* for a **pro-drug** with
perhaps the weakest basis for perpetuation pharmaceutical intellectual
patents (and thereby exorbitant drug prices)

### Healthcare Is Dangerously Expensive Because It's Disconnected From The Free-Market

Since consumers don't pull their wallet out a pharmacy, except to
cover a [hopefully] cheap copay, then they are completely disconnected
with the consequences of. Without insurance, is Vyvanse $300 or $600?
Is Adderal $40 or $80? Is brand-name adderal $400, without insurance?
YES IT IS. Does your average consumer make these decisions? NO! **Your
insurance provider and doctor make these decisions for you**, for
better or worse. Nevermind that $30 in cough/cold medication provides
sufficient precursors for 1-3g of meth, the molar equivalent to well
over 20x the active ingredient in your average Adderal prescription.

> I get so unbelievably angry thinking about how pharmaceutical
> corporations **rip off** and **bankrupt** Americans, regardless of
> whether it is by selling exorbitantly priced brand-name medications
> or *pretending to assuage the problem* of high-prescription prices
> by compromising at Federal code surrounding generic
> prescriptions. These amount to nothing other than the medical
> equivalent to Chinese Knockoffs, while being priced at 100-1000x the
> cost to produce.

AND WORST OF ALL: THE RACEMIC PROFILE GENERIC MEDICATIONS IS OFTEN
UNCHECKED! THIS MEANS THESE MEDICATIONS DON'T WORK WELL AND CAUSE SIDE
EFFECTS. YOU ARE BEING LIED TO, CONNED AND SLOW-POISONED BY
GREED-DRIVEN ASSHOLES WITH COLLEGE DEGREES IN MAJORS WHERE THEY SHOULD
KNOW BETTER: THEY'RE COGNIZANT.





### Case In Point: Racemic Compositions of Generic Adderal

  - Consider adderal, a drug for which generics I have
    noticed introduce bad side effects with completely different
    profiles. Why? Because of the varying affinity for amphetamine's
    enantiomers to active sites in (X .. and Y) proteins. ![Picture of
    neuropharmacological pathways]()
  - What is prescribed is often simply the generic formulation of
    "amphetamine salts". Still, amphetamine salts, plural, is
    sufficiently similar to any singular amphetamine salt, singular,
    as to expect similar neuropharmacological impact. The major
    differences in the composition of various amphetamine salts (in
    instant release adderal) is that they dissolve at *slightly*
    different rates, depending on the affinity of freebase amphetamine
    to remain bonded to it's specific salt: (sulfor, ...). The salts
    dissolve quickly, enter your blood stream and thus effect mostly
    the intake and peak of plasma concentrations. Each salt has
    slightly different osmotic and hydrostatic characteristics -- with
    regard to the pH of a solution and other factors -- and thus
    reaches the blood stream at various rates. The only factor that
    limits adderall taken orally from reaching the bloodstream is the
    pH of the stomach. Here, some amphetamine salts may tend to
    release their coupled freebase moresoe in the stomach than
    later in the gastrointestinal tract, thereby resulting in the
    adderals decomposition via acidic pH.

  - What results in a much greater effect is the impact that specific
    enantiomers have on the (Pk, Pi, etc) rate's for active sites in
    neuropharmacological profiles



### Pharmacological Research Conducted Is *Worthless* Without Regard For The Profile Racemic Composition

This can impacts the number










### My current intuition (thoughts from 10/19 livestream)

### Solutions for NavierStokes are not Guaranteed, but sometimes may exist.

The overview of the #Intuition here: adding the #Viscosity to the
#NavierStokes equations results in an invalid construction. It is
confusing because there are some configurations of the N/S equations
that may result in examples of exact/potential solutions, but I don't
believe that existence is guaranteed for those solutions. This is
counterintuitive, since analytical methods can usually refine
approximated solutions; their approximations may even deceptively
proceed towards some singular point in solution-space; #SobolevSpaces
may even filter the solution-space of the PDE such that it appears
that more and more singular regions are left remaining.

However, i believe the N/S equations are fundamentally flawed in how
they non-localize the viscosity throughout the space of the PDE. For
particle-based fluid systems (thus non-ideal fluid) viscosity results
from particle-particle interactions. it is localized. That said,
Navier-Stokes *IS* still a mathematic albeit non-physical equation in
its own right and the question of whether there are solutions or not
is not related to how the idealized fluid connects to fluids whose
mechanics are dependent on particle interactions

still, assume that there are non-linear systems who do not have
precise, extant and/or unique solutions. why then, do the proofs
assume that the navier-stokes equation has solutions and that one must
start from this basis and work towards solutions. THUS, i believe the
challenge of Navier-Stokes is primarily one of **logic**, related to
proof-construction, instead of difficulty related to PDE's, algebraic
geometry, complicated means of differential inequalities, etc. the
challenge lies in figuring out how to disprove the existence of N/S
solutions, given that doing so, one must start from the faulty
assumption -- or "non-assumption" -- that N/S has solutions whatsoever
and from there work towards the negation of all solution space. this
is confounded by the existence of precise N/S solutions or solution
candidates in special cases (e.g. for special configurations of the
PDE's initial values). therefore my *intuition* here tells me that
solutions sometimes exist, may or may not be unique, but cannot be
guaranteed, which is counterintuitive, considering that N/S equations
can always be approximated by analytical methods.



# Navier Stokes

### (content from original posts)

So this new #ArsTechnica article covers #NavierStokes and
#TurbulentFlows in depth, for which there are many unsolved
problems. However, my rambling idea to revolutionize
#ChemicalEngineering by measuring changes in #Photon #Polarization
requires dealing with Navier-Stokes and turbulent flows. In the posts
& stream, there are some #NOVEL #IDEAS (i think?) for
#AnalyticalMethods in handling such flows, albeit producing additional
solutions/methods. I wonder if anyone associated with the tagged
#VirginiaTech pages even bothered to notice this... ?? Certainly, no
one mentioned it to me.

In particular, applying #MachineLearning to an experimental version of
example the #LaminarFlow regions exhibiting something like
#PhaseChange into #TurbulentFlows is why i mentioned #Kinematics in
the #Livestream. See the second pic i uploaded to understand which
example from the article i'm talking abou. The author mentions it as a
problem of theory/math, whereas I'm referring to a similar experiment
where a <200nm capillary-like tube would provide a basis for
collecting data Polarization & #SpectralDistortion that indicates how
components of the fluid moves through space and for which turbulent
regions will refract/polarize light in completely different ways IN
THE REGION BOUNDED BY THE PHASE CHANGE AND TRACKABLE WITH KINEMATIC
METHODS -- e.g. #Displacement & #Deformation.

Once refined with machine learning, this data could allow a
generalization from analytically-processed, refined data, connected to
the space of numerical solutions .... not unlike with Nash's work on
#AnalyticGeometry (see pic three) .  Furthermore, #PerturbationMethods
on the #AnalyticMachineLearning (not those applied to the theoretical
physical systems mentioned in the article) could accelerate bridging
this gap from analytic reflection on experimental data to theoretical
models -- or perhaps would be useful in getting much closer to the
answer of whether complete theoretical, numerical solutions exist
regardless of whether all numerical cases are tractable (they are not)

https://arstechnica.com/science/2018/10/turbulence-the-oldest-unsolved-problem-in-physics/

### ... Or maybe not

- these methods may not allow data science to bridge from machine
  learning models to validate Navier-Stokes' smoothness/completeness
  conjectures (by bridging them to numerical constructions via Nash
  Functions)
  - however, the techniques used to gather the data, along with the
    data science for analysis, is still very useful in identifying
    fingerprints of solute composition via kinematic inference with
    displacement/deformation.
  - for any and every stage of chemical reactions engineered for
    lab-scale or industrial scale, there are many reasons to assume
    such a mechanism to be limited in its viability. however, it might
    be exceedingly valuable for the production and sorting of
    nanotubes and nano-spheres, since their specialized shape/size
    would have a characteristic impact on the fluid's optical
    refraction. for the simplist nanotubes, other sorting techniques
    would likely be more effective.



### Post correcting racemic

Actually, in extremely confined spaces (< 200-500nm), IT IS POSSIBLE
TO DELINEATE COMPONENTS OF #RACEMIC MIXTURES USING POLARIMETRY,
KINEMATIC INFERENCES AND DATA SCIENCE.

https://www.sparknotes.com/chemistry/organic3/stereoisomers/section2=
}Why? Because influences "stack" from E/M fields of crystals (or even
{+P0Ö/;.l`}
fluids!) on polarization/refractions. Since the solution is extremely
confined, surfaces effects along its boundary also cause
stereo-specific polarization effects. Further, using #Kinematic
inference about which volumes of solution have undergone "phase
changes" of #Turbulence, whose volumes can be tracked over time, then
you can make conclusions about the how the solution's
disparate/morphing impact on configurations of molecule groups within
those volumes affects polarimetry. For example, if various volumes of
a fluid in an extremely confined space become mildly turbulent, then
those volumes will tend to cause polarimetric effects to disappear,
whereas the "entropy" of racemic configuration of other volume
elements is such that **the minor polarimetric effects remain
distinguishable.**

So you CAN use polarimetry, but the mechanisms are highly dependent on
the solutes/reaction/container in the reaction pipeline.

What is unclear to me? How I could intuitively know this -- without
having learned it incorrectly, as taught by standard #OChem and #ChemE
resources like like this website? It's because I think for myself, i
have intuition, i think in pictures, and i don't think in terms of
structured logic & linguistic units & formulas that are conditioned
layer by layer requiring unlearning. If instead, one learns about
asserting #Racemic components in solution by #Polarimetry from the
requisite university, it's easy to see that person claim I'm wrong,
without anyone around them at an engineering school raising an
eyebrow.
